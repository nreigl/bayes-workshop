---
title: "Starting with Bayes statistics by estimating a mean"
subtitle: "Simple intercept-only models"
author: "Taavi Päll and Ülo Maiväli"
date: "2021-10-02"
output: github_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading some required libraries

```{r}
library(tidyverse)
library(here)
library(brms)
library(bayesplot)
library(tidybayes)
library(modelr)
```

## Getting data

We will use USA president heights data.

### Downloading US president heights data

President heights were copy-pasted from
[potus.com](https://www.potus.com/presidential-facts/presidential-heights/)
and after preprocessing (keeping only names and height in cm) saved to
`data` subfolder in our project folder.

### Importing president heights data


```{r}
(president_heights <- read_csv(here("data/president_heights.csv"), col_types = "dcd"))
```

We have two columns in our tibble -- presidents names ("name") and
height in cm ("height_cm").

## Visualization

As always, any analysis should start with data visualization to avoid
[Datasaurus](https://itsalocke.com/datasaurus/) appearing in the end.

Simple scatter plot, starting with tallest presidents.

-   Abraham Lincoln was the tallest president at 193 cm.
-   James Madison was the shortest president at 163 cm.
-   The average height of the presidents is 180 cm.

```{r}
ggplot(data = president_heights) +
 geom_point(aes(x = height_cm, y = fct_reorder(name, height_cm))) +
 theme(axis.title.y = element_blank())
```

Histogram shows that most frequently US presidents have been 183 cm
tall.

```{r}
ggplot(data = president_heights) +
 geom_histogram(aes(x = height_cm), binwidth = 1) +
 scale_y_continuous(breaks = scales::pretty_breaks())
```


Median and standard deviation of all presidents:
```{r}
president_heights %>% 
  summarise_at("height_cm", list(median = median, sd = sd))
```


## Modeling

### Simple intercept-only model

We denote our intercept-only model like so:

$$h_i \sim \text{Normal}(\mu, \sigma)$$
$$\mu \sim \text{Normal}(178, 20)$$
$$\sigma \sim \text{Normal}(7.4, 2)$$

As for R model formula, on left side we define "height_cm" as our
response variable (must be in data) and on the right side we define that
we are interested only in modeling "Intercept".


We keep only last ten presidents in our sample, as it's is well known that 
people have become taller during last 230 years.
```{r}
(president_heights <- president_heights %>% 
  arrange(number) %>% 
  tail(10))
```


```{r}
f <- height_cm ~ 1
```

Let's have a look at the parameters in our model for which we can
specify priors and their default priors.

```{r}
get_prior(formula = f, data = president_heights, family = gaussian())
```

To fit a **brms** model, we need to specify minimally:

1.  **model formula** in lme4 syntax
2.  **data** as data.frame and
3.  **family** to specify response distribution and **link function**.

Additionally, we want to run three chains and save fitted model to a
file in `models` subfolder (next line creates this folder if missing) to
avoid always refitting when updating and rerunning the script.

If you need to refit the model, then go to models folder and delete the
model file (.rds format).

```{r}
if (!dir.exists(here("models"))) dir.create(here("models")) # we keep models only locally
```

#### Testing priors for Intercept -- uninformative prior

Here we fit intercept-only model using president heights data and
**uninformative** priors: "let data speak".

There are several reasons for using non-informative priors, including:

-   Not having any useful prior information or strong personal opinion
    upon which to base an informative prior.  
-   a non-informative prior gives a result numerically similar to a
    frequentist approach when little or no prior information is
    provided, while allowing for use of prior information when it
    exists.  
-   *ad hoc* sensitivity analysis to see how much influence a strong
    prior has had on the results of a Bayesian analysis.

```{r}
priors <- c(
  prior("normal(0, 200)", class = "Intercept"),
  prior("normal(7.6, 2)", class = "sigma")
  )
mod1 <- brm(
 formula = f, 
 data = president_heights, 
 family = gaussian(), 
 prior = priors,
 chains = 3, 
 file = here("models/height_cm~1_normal(0, 200)_Intercept_normal(7.6, 2)_sigma"),
 sample_prior = "yes"
 )
```

#### Model diagnostics

Let's have a look at our fitted model summary:

```{r}
summary(mod1)
```


**Rhat** function produces R-hat convergence diagnostic, which compares
the between- and within-chain estimates for model parameters. If chains
have not mixed well (ie, the between- and within-chain estimates don't
agree), Rhat is larger than 1. 

It's recommend to run at least four
chains by default and only using the sample if Rhat is less than 1.05.

Both **bulk-ESS** and **tail-ESS** should be at least \~100 per Markov
Chain in order to be reliable and indicate that estimates of respective
posterior quantiles are reliable.


Diagnostic plot showing posterior distributions of model parameters and 
markov chains. All chains should be nicely mixed.
```{r}
plot(mod1)
```

Model object stores also information about used prior distributions. 
Let's check our priors from model:

```{r}
mod1$prior
```


More condensed and tidy version of model summary can be generated with 
`posterior_summary()` function.
```{r}
posterior_summary(mod1)
```

#### Posterior samples

Let's extract posterior samples from our model object.

Posterior samples can be extracted from **brms** model objects simply by running 
`as.data.frame(mod)`, which returns R data.frame (not tibble!), 
so be careful printing it out into console, and convert it to tibble.

However, we suggest using `posterior_samples()` function from **brms**, 
as it's more explicit. In both cases the output is identical.

```{r}
(samples1 <- as_tibble(posterior_samples(mod1)))
```

Now we can visualize prior and posterior distributions of Intercept side-by-side:
```{r}
samples1 %>% 
 select(matches("Intercept")) %>% 
 pivot_longer(cols = matches("Intercept")) %>% 
 ggplot() +
 geom_density(aes(value, linetype = name)) +
 labs(title = str_c("Uninformative prior: ", mod1$prior[1, 1])) +
 facet_wrap(~name, ncol = 1, scales = "free_y") +
  scale_x_continuous(limits = c(100, 200))
```


#### Testing priors for Intercept -- informative prior

To specify an informative prior for Intercept, we can use
information obtained from [Wikipedia](https://en.wikipedia.org/wiki/Average_human_height_by_country), which states that average male height in Non-Hispanic Whites in USA is 178 cm (measured 2015-2018) and standard deviation 7.6 cm.


```{r}
priors <- c(
  prior("normal(178, 20)", class = "Intercept"),
  prior("normal(7.6, 2)", class = "sigma")
  )
mod2 <- brm(
  formula = f, 
  data = president_heights, 
  family = gaussian(), 
  prior = priors, 
  chains = 3, 
  file = here("models/height_cm~1_normal(178, 20)_Intercept_normal(7.6, 2)_sigma"), 
  sample_prior = "yes"
  )
summary(mod2)
```

```{r}
plot(mod2)
```

```{r}
samples2 <- as_tibble(posterior_samples(mod2))
samples2 %>% 
  select(matches("Intercept")) %>% 
  pivot_longer(cols = matches("Intercept")) %>% 
  ggplot() + 
  geom_density(aes(value, linetype = name)) + 
  labs(title = str_c("Good informative prior: ", mod2$prior[1,1])) + 
  facet_wrap(~name, ncol = 1, scales = "free_y")
```

#### Testing priors for Intercept -- bad informative prior

Now, let's see what happens when our prior is well off, suppose we got
our prior from NBA.

```{r}
priors <- c(
  prior("normal(199, 1)", class = "Intercept"),
  prior("normal(7.6, 2)", class = "sigma"))
mod3 <- brm(
  formula = f, 
  data = president_heights, 
  family = gaussian(), 
  prior = priors, 
  chains = 3, 
  file = here("models/height_cm~1_normal(199, 1)_Intercept_normal(7.6, 2)_sigma"), 
  sample_prior = "yes" 
  )
summary(mod3) 
```

```{r}
plot(mod3)
```

```{r}
samples3 <- as_tibble(posterior_samples(mod3))
samples3 %>% 
  select(matches("Intercept")) %>% 
  pivot_longer(cols = matches("Intercept")) %>% 
  ggplot() + 
  geom_density(aes(value, linetype = name)) + 
  labs(title = str_c("Bad informative prior: ", mod3$prior[1,1])) +
  facet_wrap(~name, ncol = 1, scales = "free_y")
```

Compare last result with good informative priors (compare Intercept of all these models).



#### Conclusion from using different priors

- Strong priors can have strong effect on posterior, specially when there is few data. 
This is not a bug but a feature. 
- We can see that in our models, **posterior displays less variation than
prior**, that's because posterior distribution incorporates information
from data, we can expect that it's less variable than prior
distribution.    

### Sampling from prior only

When setting up model, we can start with drawing samples solely from the priors 
ignoring the likelihood, which allows to generate samples from the prior
predictive distribution and get an idea if chosen model specification is 
reasonable and provides posteriors on expected scale.

```{r}
priors <- c(
  prior("normal(178, 20)", class = "Intercept"),
  prior("normal(7.4, 2)", class = "sigma")
  )
mod2.1 <- brm(
  formula = f, 
  data = president_heights, 
  family = gaussian(), 
  prior = priors, 
  chains = 3, 
  file = here("models/height_cm~1_prior_only"), 
  sample_prior = "only"
  )
summary(mod2.1)
```

Generating posterior predictive samples from prior-only model. 
Chosen prior seems to generate reasonable values.
Black line denotes data, blue lines denote samples from prior-predictive 
distribution.

```{r}
set.seed(12) 
pp_check(mod2.1, nsamples = 10)
```

We can use plotting functions from *bayesplot* package to generate 
diagnostic plots for summary statistics of prior-predictive samples.

For this we need our data as *y* and samples drawn from model *yrep*.

```{r}
y <- president_heights$height_cm 
yrep <- posterior_predict(mod2.1)
```

We can check mean and max values in replications:
**Mean**
```{r}
ppc_stat(y, yrep, stat = "mean", binwidth = 5)
```

**Max**
```{r}
ppc_stat(y, yrep, stat = "max", binwidth = 5)
```

Or look at custom summary statistics, e.g. quantiles
25% quantile
```{r}
q25 <- function(x) quantile(x, 0.25) 
ppc_stat(y, yrep, stat = "q25", binwidth = 5)
```

75% quantile
```{r}
q75 <- function(x) quantile(x, 0.75)
ppc_stat(y, yrep, stat = "q75", binwidth = 5)
```

Plot central quantile posterior interval estimates
```{r}
mcmc_areas(mod2.1, pars = "b_Intercept", prob = 0.5, prob_outer = 0.9)
```


```{r}
posterior_summary(mod2.1, probs = c(0.05, 0.95))
```



### Working with posterior draws
> Liiguta üles, ja too need hypothesis() funktsiooni asjad siia alla!

We can have look at variables saved in our model:
```{r}
get_variables(mod2)
```

Extract desired draws from a Bayesian model:
```{r}
samples2 <- as_tibble(posterior_samples(mod2))
```

Again, visualize posterior distribution of Intercept:
```{r}
samples2 %>% 
  ggplot() +
  geom_density(aes(b_Intercept - 178)) +
  geom_vline(xintercept = 0, linetype = "dashed")
```


Calculate summary statistics:
```{r}
posterior_summary(samples2)
```

Retest our hypothesis that US presidents are above average tall:
```{r}
samples2 %>%
  summarise(Effect.size_cm = mean(b_Intercept - 178), Post.Prob = mean((b_Intercept - 178) > 0))
```

#### Pairs plot

We can see from draws tibble that draws from each iteration have tuple of b_Intercept and sigma. Let's see how they are related in our posterior.

Samples from the posterior distribution for the heights data. 
The density of points is highest in the center, reflecting the most plausible combinations of \mu and \sigma.
```{r}
samples2 %>% 
  ggplot(aes(sigma, b_Intercept)) +
  geom_point(alpha = 1/5) +
  coord_equal()
```


More elaborate plot with :
```{r}
pairs(mod2)
```

### Compare parameters from all these three models

```{r}

```



### Bayesian estimation vs OLS

panna selle koha peale kustkohast me mudelist andmeid genereerime

Linear regression (OLS) predicts a maximum likelihood estimate of the target variable, Bayesian linear regression predicts a whole distribution over the target variable, offering a natural measure of prediction uncertainty.

Let's visualize this difference:
```{r}
set.seed(1)
samples2 <- as_tibble(posterior_samples(mod2))
a <- rnorm(1000, samples2$b_Intercept, samples2$sigma)
b <- rnorm(1000, median(samples2$b_Intercept), median(samples2$sigma))
sd(a)
sd(b)
```

- In **a** variation comes from 2 sources:    
1. the estimated SD of the normal model and     
2. the uncertainty of this estimation captured in the posterior.   
- In **b** variation comes from the (1) only. **b** corresponds to OLS estimation.   

```{r}
tibble(a = a, b = b) %>% 
  gather() %>% 
  ggplot() +
  geom_density(aes(value, color = key)) +
  scale_color_discrete(labels = c(str_c('a (SD=', signif(sd(a), 3), ')'), str_c('b (SD=', signif(sd(b), 3), ')'))) +
  theme(legend.title = element_blank(), legend.position = "bottom")
```


#### Inference from different priors -- are USA presidents taller than average

Let's compare, how much influence different priors have on inference.

We test hypothesis that USA presidents are above average tall, with
contemporary average male height 178 cm.

- Uninformative prior: "let data speak"

```{r}
president_heights %>% 
  add_epred_draws(mod1) %>% 
  ungroup() %>% 
  mutate(es = .epred - 178) %>% 
  ggplot() +
  geom_density(aes(es)) +
  geom_vline(xintercept = c(0, 3.16, 9.29), linetype = c(1, 2, 2), color = c("red", "black", "black"))
```


```{r}
president_heights %>% 
  add_epred_draws(mod1) %>% 
  ungroup() %>% 
  mean_qi(.epred - 178, .width = 0.9)
```


```{r}
samples1 %>% 
  mean_qi(b_Intercept - 178, .width = 0.9)
```


```{r}
plot(hypothesis(mod1, "Intercept > 178"), plot = FALSE)[[1]] + 
  labs(title = str_c("Uninformative prior: ", mod1$prior[1,1])) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_x_continuous(limits = c(-50, 50))
```


- Informative prior

```{r}
plot(hypothesis(mod2, "Intercept > 178"), plot = FALSE)[[1]] + 
  labs(title = str_c("Informative prior: ", mod2$prior[1,1])) +
  geom_vline(xintercept = 0, linetype = "dashed")
```

- Bad informative prior

```{r}
plot(hypothesis(mod3, "Intercept > 178"), plot = FALSE)[[1]] + 
  labs(title = str_c("Bad informative prior: ", mod3$prior[1,1])) +
  geom_vline(xintercept = 0, linetype = "dashed")
```



### Individual work 

Run models with different priors, using random sample N = 1?/2?/3/5 from presidents 
dataset.

Strong informative prior for sigma *normal(7.4, 1)*

Set seed for reproducibility!
```{r}
set.seed(20210920)
data <- sample_n(president_heights, 3)
```


TEST IT!!!

