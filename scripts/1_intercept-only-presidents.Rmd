---
title: "Starting with Bayes statistics by estimating a mean"
subtitle: "Simple intercept-only models"
author: "Taavi Päll and Ülo Maiväli"
date: "2021-10-02"
output: github_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading some required libraries

```{r}
library(tidyverse)
library(here)
library(brms)
library(bayesplot)
library(tidybayes)
library(modelr)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

## Getting data

We will start with USA president heights.

### Downloading US president heights data

President heights were copy-pasted from
[potus.com](https://www.potus.com/presidential-facts/presidential-heights/)
and after preprocessing (keeping only names and height in cm) saved to
`data` subfolder in our project folder.

### Importing president heights data


```{r}
(president_heights <- read_csv(here("data/president_heights.csv"), col_types = "dcd"))
```

We have two columns in our tibble -- presidents names ("name") and
height in cm ("height_cm").

## Visualization

As always, any analysis should start with data visualization to avoid
[Datasaurus](https://itsalocke.com/datasaurus/) appearing in the end.

Simple scatter plot, starting with tallest presidents.

-   Abraham Lincoln was the tallest president at 193 cm.
-   James Madison was the shortest president at 163 cm.
-   The average height of the presidents is 180 cm.

```{r}
ggplot(data = president_heights) +
 geom_point(aes(x = height_cm, y = fct_reorder(name, height_cm))) +
 theme(axis.title.y = element_blank())
```

Histogram shows that most frequently US presidents have been 183 cm
tall.

```{r}
ggplot(data = president_heights) +
 geom_histogram(aes(x = height_cm), binwidth = 1) +
 scale_y_continuous(breaks = scales::pretty_breaks())
```


Median and standard deviation of all presidents:
```{r}
president_heights %>% 
  summarise_at("height_cm", list(median = median, sd = sd))
```


## Modeling

### Simple intercept-only model

We denote our intercept-only model like so:

$$h_i \sim \text{Normal}(\mu, \sigma)$$
$$\mu \sim \text{Normal}(178, 20)$$
$$\sigma \sim \text{Normal}(7.4, 2)$$

As for R model formula, on left side we define "height_cm" as our
response variable (must be in data) and on the right side we define that
we are interested only in modeling "Intercept".


We keep only last ten presidents in our sample, as it's is well known that 
people have become taller during last 230 years.
```{r}
(president_heights <- president_heights %>% 
  arrange(number) %>% 
  tail(10))
```


```{r}
f <- height_cm ~ 1
```

Let's have a look at the parameters in our model for which we can
specify priors and their default priors.

```{r}
get_prior(formula = f, data = president_heights, family = gaussian())
```

To fit a **brms** model, we need to specify minimally:

1.  **model formula** in lme4 syntax
2.  **data** as data.frame and
3.  **family** to specify response distribution and **link function**.

Additionally, we want to run three chains and save fitted model to a
file in `models` subfolder (next line creates this folder if missing) to
avoid always refitting when updating and rerunning the script.

If you need to refit the model, then go to models folder and delete the
model file (.rds format).

```{r}
if (!dir.exists(here("models"))) dir.create(here("models")) # we keep models only locally
```

#### Testing priors for Intercept -- uninformative prior

Here we fit intercept-only model using president heights data and
**uninformative** priors: "let data speak".

There are several reasons for using non-informative priors, including:

-   Not having any useful prior information or strong personal opinion
    upon which to base an informative prior.  
-   a non-informative prior gives a result numerically similar to a
    frequentist approach when little or no prior information is
    provided, while allowing for use of prior information when it
    exists.  
-   *ad hoc* sensitivity analysis to see how much influence a strong
    prior has had on the results of a Bayesian analysis.

```{r}
priors <- c(
  prior("normal(0, 200)", class = "Intercept"),
  prior("normal(7.6, 2)", class = "sigma")
  )
mod1 <- brm(
 formula = height_cm ~ 1, 
 data = president_heights, 
 family = gaussian(), 
 prior = priors,
 chains = 3, 
 iter = 2400,
 file = here("models/height_cm~1_normal(0, 200)_Intercept_normal(7.6, 2)_sigma"),
 sample_prior = "yes",
 file_refit = "on_change"
 )
```

#### Model diagnostics

Let's have a look at our fitted model summary:

```{r}
summary(mod1)
```


**Rhat** function produces R-hat convergence diagnostic, which compares
the between- and within-chain estimates for model parameters. If chains
have not mixed well (ie, the between- and within-chain estimates don't
agree), Rhat is larger than 1. 

It's recommend to run at least four
chains by default and only using the sample if Rhat is less than 1.05.

Both **bulk-ESS** and **tail-ESS** should be at least \~100 per Markov
Chain in order to be reliable and indicate that estimates of respective
posterior quantiles are reliable.


Diagnostic plot showing posterior distributions of model parameters and 
markov chains. All chains should be nicely mixed.
```{r}
plot(mod1)
```

Model object stores also information about used prior distributions. 
Let's check our priors from model:

```{r}
mod1$prior
```


More condensed and tidy version of model summary can be generated with 
`posterior_summary()` function.
```{r}
posterior_summary(mod1)
```

```{r}
mod1 <- brm(height_cm ~ 1, data = president_heights)
```

```{r}
summary(mod1)
```


#### Posterior samples

Let's extract posterior samples from our model object.

Posterior samples saved in **brms** model objects can be extracted by running 
`as.data.frame(mod)`, which returns R data.frame (not tibble!), 
so be careful printing it out into console, and convert it to tibble.

However, we suggest using `posterior_samples()` function from **brms**, 
as it does same thing but is more explicit. 
In both cases the output is identical.   

```{r}
(samples1 <- as_tibble(posterior_samples(mod1)))
```

```{r}
as_draws_df(mod1)
?as_draws_df
```


Now we can visualize prior and posterior distributions of Intercept side-by-side:

```{r}
samples1 %>% 
 select(matches("Intercept")) %>% 
 pivot_longer(cols = matches("Intercept")) %>% 
 ggplot() +
 geom_density(aes(value, linetype = name)) +
 labs(title = str_c("Uninformative prior: ", mod1$prior[1, 1])) +
 facet_wrap(~name, ncol = 1, scales = "free_y") +
  scale_x_continuous(limits = c(100, 200))
```


#### Testing priors for Intercept -- informative prior

To specify an informative prior for Intercept, we can use
information obtained from [Wikipedia](https://en.wikipedia.org/wiki/Average_human_height_by_country), which states that average male height in Non-Hispanic Whites in USA is 178 cm (measured 2015-2018) and additionally we have found from the internet that standard deviation of male 
height is 7.6 cm.


```{r}
priors <- c(
  prior("normal(178, 2)", class = "Intercept"),
  prior("normal(7, 1)", class = "sigma")
  )
mod2 <- brm(
  formula = f, 
  data = president_heights, 
  family = gaussian(), 
  prior = priors, 
  chains = 3, 
  file = here("models/height_cm~1_normal(178, 2)_Intercept_normal(7, 1)_sigma"), 
  sample_prior = "yes"
  )
summary(mod2)
```

```{r}
plot(mod2)
```

```{r}
samples2 <- as_tibble(posterior_samples(mod2))
samples2 %>% 
  select(matches("Intercept")) %>% 
  pivot_longer(cols = matches("Intercept")) %>% 
  ggplot() + 
  geom_density(aes(value, linetype = name)) + 
  labs(title = str_c("Good informative prior: ", mod2$prior[1,1])) + 
  facet_wrap(~name, ncol = 1, scales = "free_y")
```

```{r}
m <- lm(f, president_heights)
m
```


#### Testing priors for Intercept -- bad informative prior

Now, let's see what happens when our prior is well off, suppose we got
our prior from NBA.

```{r}
priors <- c(
  prior("normal(199, 1)", class = "Intercept"),
  prior("normal(7.6, 2)", class = "sigma"))
mod3 <- brm(
  formula = f, 
  data = president_heights, 
  family = gaussian(), 
  prior = priors, 
  chains = 3, 
  file = here("models/height_cm~1_normal(199, 1)_Intercept_normal(7.6, 2)_sigma"), 
  sample_prior = "yes" 
  )
summary(mod3) 
```

```{r}
plot(mod3)
```

```{r}
samples3 <- as_tibble(posterior_samples(mod3))
samples3 %>% 
  select(matches("Intercept")) %>% 
  pivot_longer(cols = matches("Intercept")) %>% 
  ggplot() + 
  geom_density(aes(value, linetype = name)) + 
  labs(title = str_c("Bad informative prior: ", mod3$prior[1,1])) +
  facet_wrap(~name, ncol = 1, scales = "free_y")
```

Compare last result with good informative priors (compare Intercept of all these models).


### Comparing parameters from all these three models

We have samples from three models: samples1..3.
Let's compare b_Intercept and sigma:

```{r}
list(`Non-inform.` = samples1, `Inform.` = samples2, `Bad inform.` = samples3) %>% 
  bind_rows(.id = "model") %>% 
  select(model, b_Intercept, sigma) %>% 
  pivot_longer(cols = c("b_Intercept", "sigma")) %>% 
  ggplot(aes(fct_reorder(model, desc(model)), value)) +
  stat_pointinterval(position = "dodge", .width = c(0.67, 0.95)) +
  facet_wrap(~name, scales = "free") +
  labs(x = "Prior type")
```


#### Conclusion from using different priors

- Strong priors can have strong effect on posterior, specially when there is few data. 
This is not a bug but a feature. 
- Additionally, we can see from our models that **posterior displays less variation than
prior**, that's because posterior distribution incorporates information
from data, therefore we can expect that it's less variable than prior
distribution.    


### Sampling from prior only

When setting up model, we can start with drawing samples solely from the priors 
ignoring the likelihood, which allows to generate samples from the prior
predictive distribution and get an idea if chosen model specification is 
reasonable and provides posteriors on expected scale.

```{r}
priors <- c(
  prior("normal(178, 2)", class = "Intercept"),
  prior("normal(7, 1)", class = "sigma")
  )
mod2.1 <- brm(
  formula = f, 
  data = president_heights, 
  family = gaussian(), 
  prior = priors, 
  chains = 3, 
  file = here("models/height_cm~1_prior_only"), 
  sample_prior = "only"
  )
summary(mod2.1)
```

Generating posterior predictive samples/plot from prior-only model. 

```{r}
set.seed(12) 
pp_check(mod2.1, nsamples = 100)
```

Chosen prior seems to generate reasonable values.
Black line denotes data, blue lines denote samples from prior-predictive 
distribution.

Run `pp_check()` multiple times to get an idea where samples generated from 
prior land.






We can use plotting functions from *bayesplot* package to generate 
diagnostic plots for summary statistics of prior-predictive samples.

For this we need our data as *y* and samples drawn from model *yrep*.

```{r}
y <- president_heights$height_cm 
yrep <- posterior_predict(mod2.1)
```

We can check mean and max values in replications:
**Mean**
```{r}
ppc_stat(y, yrep, stat = "mean", binwidth = 1)
```

**Max**
```{r}
ppc_stat(y, yrep, stat = "max", binwidth = 1)
```

Or look at custom summary statistics, e.g. quantiles
25% quantile
```{r}
q25 <- function(x) quantile(x, 0.25) 
ppc_stat(y, yrep, stat = "q25", binwidth = 1)
```

75% quantile
```{r}
q75 <- function(x) quantile(x, 0.75)
ppc_stat(y, yrep, stat = "q75", binwidth = 1)
```

Plot central quantile posterior interval estimates
```{r}
mcmc_areas(mod2.1, pars = "b_Intercept", prob = 0.5, prob_outer = 0.9)
```

We can also run posterior summary function to check e.g. 90% quantile intervals:
```{r}
posterior_summary(mod2.1, probs = c(0.05, 0.95))
```


#### Pairs plot

We can see from posterior samples that each draw/row contains a tuple of estimated parameters e.g. b_Intercept and sigma. Let's see how they are related in our posterior.

We will use posterior samples from our informative prior model. 
The density of points is highest in the center, reflecting the most plausible combinations of \mu and \sigma.
```{r}
samples2 %>% 
  ggplot(aes(sigma, b_Intercept)) +
  geom_point(alpha = 1/5) +
  coord_equal()
```


More elaborate plot with :
```{r}
pairs(mod2)
```

Correlation between intercept and sigma can be calculated like so:
```{r}
samples2 %>% 
  select(b_Intercept, sigma) %>% 
  cor()
```

```{r}
cor(select(samples2, b_Intercept, sigma))
```

### Bayesian estimation vs OLS

Linear regression (OLS) predicts a maximum likelihood estimate of the target variable, Bayesian linear regression predicts a whole distribution over the target variable, offering a natural measure of prediction uncertainty.

Let's visualize this difference:
```{r}
set.seed(1)
samples2 <- as_tibble(posterior_samples(mod2))
a <- rnorm(3000, samples2$b_Intercept, samples2$sigma)
b <- rnorm(3000, mean(samples2$b_Intercept), mean(samples2$sigma))
sd(a)
sd(b)
```

- In **a** variation comes from 2 sources:    
1. the estimated SD of the normal model and     
2. the uncertainty of this estimation captured in the posterior.   
- In **b** variation comes from the (1) only. **b** corresponds to OLS estimation.   

```{r}
tibble(a = a, b = b) %>% 
  gather() %>% 
  ggplot() +
  geom_density(aes(value, color = key)) +
  scale_color_discrete(labels = c(str_c('a (SD=', signif(sd(a), 3), ')'), str_c('b (SD=', signif(sd(b), 3), ')'))) +
  theme(legend.title = element_blank(), legend.position = "bottom")
```


#### Inference from different priors -- are USA presidents taller than average

Let's compare, how much influence different priors have on inference.

But first, what's the difference between linpred, epred and predicted draws?
Jonah Gabry explains difference on <https://discourse.mc-stan.org> as follows:

Suppose we have a negative binomial regression with a log link:

$$\eta_i = \alpha + \beta x_i$$
$$\lambda_i = exp(\eta_i)$$
$$y \sim NegBinom(\lambda_i, \phi)$$

- `posterior_linpred()` gives you posterior draws of $\eta$.
- `posterior_linpred(transform = TRUE)`, or equivalently `posterior_epred()`, gives you posterior draws of $\lambda$, that is, it does the inverse link transformation for you.
- `posterior_predict()` gives you draws from $NegBinom(\lambda, \phi)$, that is it uses a NegBinom random number generator and includes the dispersion information in $\phi$.


We test hypothesis that USA presidents are above average tall, with
contemporary average male height 178 cm.

- Uninformative prior: "let data speak"

First, we can calculate effect size manually, and we want to use 
`posterior_epred`, as we want to test or hypothesis on same scale as our 
original values (we used identity link anyway):

```{r}
post1 <- president_heights %>% 
  add_epred_draws(mod1) %>% 
  ungroup()
```


Quantile intervals:
```{r}
post1 %>% 
  mean_qi(.epred - 178, .width = 0.9)
```

Plot quantile intervals:
```{r}
post1 %>% 
  mutate(es = .epred - 178) %>% 
  ggplot() +
  geom_density(aes(es)) +
  geom_vline(xintercept = c(0, 3.16, 9.29), linetype = c(1, 2, 2), color = c("red", "black", "black"))
```

How much of our effect size is above 0:
```{r}
post1 %>% 
  summarise(`P(height > 178)` = mean((.epred - 178) > 0))
```

There's function `hypothesis` that allows non-linear hypothesis testing for all 
model parameters.
```{r}
?hypothesis
```


```{r}
(h1 <- hypothesis(mod1, "Intercept > 178"))
```



```{r}
plot(h1, plot = FALSE)[[1]] + 
  labs(title = str_c("Uninformative prior: ", mod1$prior[1,1])) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_x_continuous(limits = c(-50, 50))
```


- Informative prior

```{r}
(h2 <- hypothesis(mod2, "Intercept > 178"))
```

```{r}
plot(h2, plot = FALSE)[[1]] + 
  labs(title = str_c("Informative prior: ", mod2$prior[1,1])) +
  geom_vline(xintercept = 0, linetype = "dashed")
```

- Bad informative prior

```{r}
(h3 <- hypothesis(mod3, "Intercept > 178"))
```


```{r}
plot(h3, plot = FALSE)[[1]] + 
  labs(title = str_c("Bad informative prior: ", mod3$prior[1,1])) +
  geom_vline(xintercept = 0, linetype = "dashed")
```



### Individual work 

We have a selection of Estonian male and female heights (see below, and choose either sex) from <https://buduaar.tv3.ee/seltskonnauudised/edetabel-kui-pikad-on-kuulsad-eesti-mehed/> and <https://elu24.postimees.ee/799776/loe-ja-imesta-kui-pikad-on-tuntud-eesti-naised>.

We want you to fit model and test hypothesis that these men/women are taller than average 
Estonian of same sex.
We leave it to you to find average male/female height in Estonia and choosing priors.


```{r}
(male_heights <- read_csv("
name, height
Martin Müürsepp, 208
Sten-Erik Jantson, 204
Rivo Vesik, 200
Kristjan Sarv, 198 
Jaanus Saks, 197 
Mart Sander, 196
Karl-Erik Taukar, 193
Koit Toome, 192
Rauno Märks, 192
Margus Vaher, 190
Sven Soiver, 189
Rasmus Mägi, 188
Hendrik Toompere jr, 187
Toomas Hendrik Ilves, 186
Hendrik Adler, 186
Martin Saar, 186
Tanel Padar, 186
Karl-Mihkel Salong, 185
Mikk Mäe, 185
Rolf Junior, 184.5 
Ženja Fokin, 184 
Rasmus Kaljujärv, 184
Uku Suviste, 184
Jüri Pootsmann, 183
Indrek Raadik, 182
Ott Lepland, 180.5
Mart Laar, 180
Rasmus Rändvee, 179
Ardo Kaljuvee, 179
Lauri Pedaja, 177
Allan Roosileht, 174
Erkki Sarapuu, 172"))
```

```{r}
(female_heights <- read_csv("name, height
Kati Toots, 169
Monika Tuvi, 169
Kerli Kõiv, 157
Merlyn Uusküla, 165
Merliis Rinne, 164
Anna-Maria Galojan, 162
Laura Kõrgemäe, 178
Siiri Sõnajalg, 176.5
Viivi Sõnajalg, 178
Beatrice, 173
Ines Karu-Salo, 171
Jana Kask, 171
Jana Pulk, 168
Maarja-Liis Ilus, 170
Kristiina Aigro, 176
Kaia Kanepi, 181
Evelyn Sepp, 182
"))
```


```{r}

```

